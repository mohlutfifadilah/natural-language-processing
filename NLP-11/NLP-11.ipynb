{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef223f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beli', 'belum', 'berakhir', 'blt', 'dolar', 'ekonomi', 'indonesia', 'inflasi', 'jual', 'kartu', 'korona', 'moneter', 'naik', 'pandemi', 'pasar', 'pertumbuhan', 'phk', 'prakerja', 'psbb', 'reses', 'saham', 'turun', 'tutup', 'uang', 'untung']\n",
      "[[0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 2 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 2 0]\n",
      " [0 0 0 0 0 1 0 2 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#Contoh Dokumen\n",
    "d1 = \"Pandemi korona indonesia belum berakhir psbb blt kartu prakerja\" #Topik 0: pandemi\n",
    "d2 = \"ekonomi reses dolar naik phk inflasi pertumbuhan ekonomi\" #Topik 1: ekonomi\n",
    "d3 = \"ekonomi uang moneter pasar uang jual beli turun tutup reses\" #Topik 1: ekonomi\n",
    "d4 = \"inflasi uang pasar saham jual untung ekonomi turun inflasi\" #Topik 1: ekonomi\n",
    "#d5 = \"teknologi gadget internet smartphone android informasi\"\n",
    "#Gabungkan dokumen menjadi satu list -> Corpus\n",
    "Docs = [d1, d2, d3, d4]\n",
    "#Ekstraksi fitur / representasi dokumen menggunakan TF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf_vectorizer = CountVectorizer(max_df=1.0, min_df=1)\n",
    "tf = tf_vectorizer.fit_transform(Docs)\n",
    "#hasil representasi\n",
    "tf_terms = tf_vectorizer.get_feature_names()\n",
    "print(tf_vectorizer.get_feature_names())\n",
    "matrix = tf.toarray()\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6db4956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=3, random_state=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# panggil class LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "n_topics = 3 #untuk mendapatkan jumlah topik terbaik perlu trial\n",
    "lda = LDA(n_components=n_topics, learning_method='batch', random_state=0).fit(tf)\n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd991f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.93231556, 0.03412529, 0.03355915],\n",
       "       [0.03924175, 0.03769985, 0.9230584 ],\n",
       "       [0.03251976, 0.03084973, 0.93663051],\n",
       "       [0.9210004 , 0.03403642, 0.04496318]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training LDA\n",
    "vsm_topics = lda.transform(tf)\n",
    "#tampilkan hasil\n",
    "print(vsm_topics.shape)\n",
    "vsm_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475abb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33361493 1.33220356 1.33220356 1.33220356 0.33367267 1.29806683\n",
      "  1.33220356 2.33534335 1.32575752 1.33220356 1.33220356 0.33361493\n",
      "  0.33367267 1.33220356 1.32575752 0.33367267 0.33367267 1.33220356\n",
      "  1.33220356 0.33362656 1.33183967 1.32575752 0.33361493 1.31157175\n",
      "  1.33183967]\n",
      " [0.33411362 0.3342122  0.3342122  0.3342122  0.33431432 0.33506001\n",
      "  0.3342122  0.33514705 0.33499564 0.3342122  0.3342122  0.33411362\n",
      "  0.33431432 0.3342122  0.33499564 0.33431432 0.33431432 0.3342122\n",
      "  0.3342122  0.33416472 0.33421601 0.33499564 0.33411362 0.33495281\n",
      "  0.33421601]\n",
      " [1.33227145 0.33358425 0.33358425 0.33358425 1.33201301 3.36687316\n",
      "  0.33358425 1.3295096  1.33924685 0.33358425 0.33358425 1.33227145\n",
      "  1.33201301 0.33358425 1.33924685 1.33201301 1.33201301 0.33358425\n",
      "  0.33358425 2.33220872 0.33394432 1.33924685 1.33227145 2.35347544\n",
      "  0.33394432]]\n"
     ]
    }
   ],
   "source": [
    "#Tampilkan nilai-nilai setiap fitur\n",
    "print(lda.components_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a5ce53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hasil label topic model untuk setiap dokumen\n",
    "import numpy as np\n",
    "topics = np.argmax(vsm_topics, axis=1)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4a4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mencetak word fitur dengan nilai tertinggi pada setiap topik\n",
    "n_top_words = 4 # jumlah fitur tertinggi yang kita tentukan\n",
    "topic_words = {}\n",
    "for topic, comp in enumerate(lda.components_):\n",
    " word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    " # store the words most relevant to the topic\n",
    " topic_words[topic] = [tf_vectorizer.get_feature_names()[i]+' '+str(comp[i]) for i in word_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7b5f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      " inflasi 2.335343346391772, pandemi 1.3322035561949337, belum 1.3322035561949337, kartu 1.3322035561949337\n",
      "Topic: 1\n",
      " inflasi 0.33514704880953633, ekonomi 0.3350600077761751, pasar 0.3349956360714814, turun 0.3349956360714814\n",
      "Topic: 2\n",
      " ekonomi 3.366873157277532, uang 2.3534754366602657, reses 2.3322087189684098, turun 1.3392468468277479\n"
     ]
    }
   ],
   "source": [
    "for topic, words in topic_words.items():\n",
    " print('Topic: %d' % topic)\n",
    " print(' %s' % ', '.join(words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02534353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Sastrawi\n",
    "import math # untuk perhitungan bobot sentence\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d7be22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pemrosesan bahasa alami (NLP) adalah sebuah teknologi machine learning yang memberi komputer kemampuan untuk menginterpretasikan, memanipulasi, dan memahami bahasa manusia. Banyak organisasi dewasa ini memiliki begitu banyak data suara dan teks dari berbagai saluran komunikasi seperti email, pesan teks, umpan berita media sosial, video, audio, dan banyak lagi. Organisasi tersebut menggunakan perangkat lunak NLP untuk memproses data ini secara otomatis, menganalisis maksud atau sentimen dalam pesan, dan merespons komunikasi manusia dalam waktu nyata.\n",
      "Pemrosesan bahasa alami sangat penting untuk sepenuhnya menganalisis data teks dan ucapan secara efisien. Teknologi ini dapat menjelajahi berbagai perbedaan dalam dialek, bahasa gaul, dan penyimpangan tata bahasa yang khas dalam percakapan sehari-hari.\n",
      "Para peneliti menggunakan data yang diproses sebelumnya untuk melatih model NLP dengan machine learning guna melakukan aplikasi spesifik berdasarkan informasi tekstual yang disediakan. Melatih algoritme NLP membutuhkan mengumpan perangkat lunak dengan sampel data besar untuk meningkatkan akurasinya.\n",
      "Ahli machine learning kemudian melakukan deployment model atau mengintegrasikan model tersebut ke dalam lingkungan produksi yang sudah ada. Model NLP menerima input dan memprediksi output untuk kasus penggunaan spesifik yang didesain untuk model tersebut. Anda dapat menjalankan aplikasi NLP di data langsung dan mendapatkan output yang diperlukan.\n",
      "NLP (Natural Language Processing) sering sekali kita temui di kehidupan sehari-hari. Misalnya ketika Anda memesan ojek online, Anda harus memilih titik di peta sesuai lokasi. Dengan bantuan NLP, pemilihan titik lokasi menjadi lebih sesuai dan tepat. Dengan semakin meningkatnya jumlah data tidak terstruktur dalam bentuk teks, suara dan video setiap harinya, NLP akan menjadi semakin penting untuk memahami data yang beredar di antara kita.\n",
      "Peningkatan kemampuan teknologi membuat NLP dapat diterapkan serta dikembangkan ke berbagai aplikasi penting lainnya untuk meningkatkan produktivitas manusia. Mengenai hal tersebut, pada artikel kali ini, kami akan ulas lebih detail dan lengkap apa yang dimaksud dengan data modeling, serta penggunaanya.\n",
      "Perangkat smart home pada umumnya, seperti Alexa dan Google Home, saat ini semakin populer, terutama di kalangan generasi muda. Dilansir oleh Digitized House, sebanyak 58% generasi muda saat ini banyak memiliki perangkat smart home dengan kemampuan kontrol suara. Smart home mudah digunakan untuk keperluan multitasking seperti Anda ingin memutar musik. Tak cuma itu, Anda sibuk memasak makan malam misalnya, Anda cukup menginstruksikan Google Home untuk mengaktifkan daftar memutar musik favorit Anda, kemudian perangkat itu akan melakukannya segera.\n",
      "Di sebagian besar rumah sakit atau klinik, pasien akan memberikan informasi tentang gejala mereka kepada perawat atau staf di konter, dan mereka akan membuat catatan untuk dibagikan ke dokter ahlinya untuk ditindaklanjuti secara. Faktanya, banyak rumah sakit atau klinik sekarang menggunakan NLP untuk merampingkan informasi pasien dan mengotomatiskan proses memahami kondisi pasien. Untuk melakukan ini dengan menggunakan NLP, biasanya rumah sakit atau klinik memungkinkan pasien berbagi pesan informasi dengan lebih cepat dan mudah.\n",
      "Natural language processing (NLP) merupakan kemampuan program komputer untuk menganalisis, memahami, dan memperoleh makna dari bahasa manusia dengan cara yang cerdas dan bermanfaat, baik bahasa lisan maupun tulisan. Dengan memanfaatkan NLP, developer dapat mengatur dan menyusun pengetahuan untuk melakukan tugas-tugas seperti peringkasan dokumen/teks otomatis, menerjemahkan teks dari satu bahasa ke bahasa lain, analisis sentimen, named entity recognition, relationship extraction, dan speech recognition.\n",
      "NLP memungkinkan komputer untuk memahami bahasa alami seperti yang dilakukan manusia. NLP menggunakan kecerdasan buatan untuk mengambil input, memprosesnya, dan memahaminya dengan cara yang dapat dipahami komputer. Sama seperti manusia yang memiliki sensor yang berbeda -- seperti telinga untuk mendengar dan mata untuk melihat -- komputer memiliki program untuk membaca teks dan mikrofon untuk mengumpulkan audio.\n",
      "Natural Language Generation adalah proses menghasilkan frasa dan kalimat yang bermakna dalam bentuk bahasa alami. Natural Language Generation menggunakan database untuk menentukan semantik di balik kata-kata dan menghasilkan teks baru. Pada intinya, NLG secara otomatis menghasilkan narasi yang menggambarkan, meringkas atau menjelaskan input data terstruktur layaknya manusia dengan kecepatan ribuan halaman per detik. NLG dapat secara otomatis menghasilkan artikel berita atau tweet berdasarkan body teks tertentu.\n",
      "Manfaat utama NLP adalah meningkatkan cara manusia dan komputer berkomunikasi satu sama lain. Cara paling langsung untuk memanipulasi komputer adalah melalui kode -- bahasa komputer. Dengan memungkinkan komputer untuk memahami bahasa manusia, berinteraksi dengan komputer menjadi jauh lebih intuitif bagi manusia.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filenames = ['tugas1.txt', 'tugas2.txt','tugas3.txt']\n",
    "  \n",
    "# Open file3 in write mode\n",
    "with open('merge-file.txt', 'w') as outfile:\n",
    "  \n",
    "    # Iterate through list\n",
    "    for names in filenames:\n",
    "  \n",
    "        # Open each file in read mode\n",
    "        with open(names) as infile:\n",
    "  \n",
    "            # read the data from file1 and\n",
    "            # file2 and write it in file3\n",
    "            outfile.write(infile.read())\n",
    "  \n",
    "        # Add '\\n' to enter data of file2\n",
    "        # from next line\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "f = open('merge-file.txt', 'r')\n",
    "dokumen = f.read()\n",
    "print(dokumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46ff2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pemrosesan bahasa alami (nlp) adalah sebuah teknologi machine learning yang memberi komputer kemampuan untuk menginterpretasikan memanipulasi dan memahami bahasa manusia. banyak organisasi dewasa ini memiliki begitu banyak data suara dan teks dari berbagai saluran komunikasi seperti email pesan teks umpan berita media sosial video audio dan banyak lagi. organisasi tersebut menggunakan perangkat lunak nlp untuk memproses data ini secara otomatis menganalisis maksud atau sentimen dalam pesan dan merespons komunikasi manusia dalam waktu nyata.\n",
      "pemrosesan bahasa alami sangat penting untuk sepenuhnya menganalisis data teks dan ucapan secara efisien. teknologi ini dapat menjelajahi berbagai perbedaan dalam dialek bahasa gaul dan penyimpangan tata bahasa yang khas dalam percakapan seharihari.\n",
      "para peneliti menggunakan data yang diproses sebelumnya untuk melatih model nlp dengan machine learning guna melakukan aplikasi spesifik berdasarkan informasi tekstual yang disediakan. melatih algoritme nlp membutuhkan mengumpan perangkat lunak dengan sampel data besar untuk meningkatkan akurasinya.\n",
      "ahli machine learning kemudian melakukan deployment model atau mengintegrasikan model tersebut ke dalam lingkungan produksi yang sudah ada. model nlp menerima input dan memprediksi output untuk kasus penggunaan spesifik yang didesain untuk model tersebut. anda dapat menjalankan aplikasi nlp di data langsung dan mendapatkan output yang diperlukan.\n",
      "nlp (natural language processing) sering sekali kita temui di kehidupan seharihari. misalnya ketika anda memesan ojek online anda harus memilih titik di peta sesuai lokasi. dengan bantuan nlp pemilihan titik lokasi menjadi lebih sesuai dan tepat. dengan semakin meningkatnya jumlah data tidak terstruktur dalam bentuk teks suara dan video setiap harinya nlp akan menjadi semakin penting untuk memahami data yang beredar di antara kita.\n",
      "peningkatan kemampuan teknologi membuat nlp dapat diterapkan serta dikembangkan ke berbagai aplikasi penting lainnya untuk meningkatkan produktivitas manusia. mengenai hal tersebut pada artikel kali ini kami akan ulas lebih detail dan lengkap apa yang dimaksud dengan data modeling serta penggunaanya.\n",
      "perangkat smart home pada umumnya seperti alexa dan google home saat ini semakin populer terutama di kalangan generasi muda. dilansir oleh digitized house sebanyak 58% generasi muda saat ini banyak memiliki perangkat smart home dengan kemampuan kontrol suara. smart home mudah digunakan untuk keperluan multitasking seperti anda ingin memutar musik. tak cuma itu anda sibuk memasak makan malam misalnya anda cukup menginstruksikan google home untuk mengaktifkan daftar memutar musik favorit anda kemudian perangkat itu akan melakukannya segera.\n",
      "di sebagian besar rumah sakit atau klinik pasien akan memberikan informasi tentang gejala mereka kepada perawat atau staf di konter dan mereka akan membuat catatan untuk dibagikan ke dokter ahlinya untuk ditindaklanjuti secara. faktanya banyak rumah sakit atau klinik sekarang menggunakan nlp untuk merampingkan informasi pasien dan mengotomatiskan proses memahami kondisi pasien. untuk melakukan ini dengan menggunakan nlp biasanya rumah sakit atau klinik memungkinkan pasien berbagi pesan informasi dengan lebih cepat dan mudah.\n",
      "natural language processing (nlp) merupakan kemampuan program komputer untuk menganalisis memahami dan memperoleh makna dari bahasa manusia dengan cara yang cerdas dan bermanfaat baik bahasa lisan maupun tulisan. dengan memanfaatkan nlp developer dapat mengatur dan menyusun pengetahuan untuk melakukan tugastugas seperti peringkasan dokumenteks otomatis menerjemahkan teks dari satu bahasa ke bahasa lain analisis sentimen named entity recognition relationship extraction dan speech recognition.\n",
      "nlp memungkinkan komputer untuk memahami bahasa alami seperti yang dilakukan manusia. nlp menggunakan kecerdasan buatan untuk mengambil input memprosesnya dan memahaminya dengan cara yang dapat dipahami komputer. sama seperti manusia yang memiliki sensor yang berbeda  seperti telinga untuk mendengar dan mata untuk melihat  komputer memiliki program untuk membaca teks dan mikrofon untuk mengumpulkan audio.\n",
      "natural language generation adalah proses menghasilkan frasa dan kalimat yang bermakna dalam bentuk bahasa alami. natural language generation menggunakan database untuk menentukan semantik di balik katakata dan menghasilkan teks baru. pada intinya nlg secara otomatis menghasilkan narasi yang menggambarkan meringkas atau menjelaskan input data terstruktur layaknya manusia dengan kecepatan ribuan halaman per detik. nlg dapat secara otomatis menghasilkan artikel berita atau tweet berdasarkan body teks tertentu.\n",
      "manfaat utama nlp adalah meningkatkan cara manusia dan komputer berkomunikasi satu sama lain. cara paling langsung untuk memanipulasi komputer adalah melalui kode  bahasa komputer. dengan memungkinkan komputer untuk memahami bahasa manusia berinteraksi dengan komputer menjadi jauh lebih intuitif bagi manusia.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "dokumen = dokumen.lower()\n",
    "dokumen = dokumen.replace(',',\"\")\n",
    "dokumen = dokumen.replace('-',\"\")\n",
    "dokumen = dokumen.replace('/',\"\")\n",
    "print(dokumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df688636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pemrosesan bahasa alami (nlp) adalah sebuah teknologi machine learning yang memberi komputer kemampuan untuk menginterpretasikan memanipulasi dan memahami bahasa manusia. banyak organisasi dewasa ini memiliki begitu banyak data suara dan teks dari berbagai saluran komunikasi seperti email pesan teks umpan berita media sosial video audio dan banyak lagi. organisasi tersebut menggunakan perangkat lunak nlp untuk memproses data ini secara otomatis menganalisis maksud atau sentimen dalam pesan dan merespons komunikasi manusia dalam waktu nyata.', 'pemrosesan bahasa alami sangat penting untuk sepenuhnya menganalisis data teks dan ucapan secara efisien. teknologi ini dapat menjelajahi berbagai perbedaan dalam dialek bahasa gaul dan penyimpangan tata bahasa yang khas dalam percakapan seharihari.', 'para peneliti menggunakan data yang diproses sebelumnya untuk melatih model nlp dengan machine learning guna melakukan aplikasi spesifik berdasarkan informasi tekstual yang disediakan. melatih algoritme nlp membutuhkan mengumpan perangkat lunak dengan sampel data besar untuk meningkatkan akurasinya.', 'ahli machine learning kemudian melakukan deployment model atau mengintegrasikan model tersebut ke dalam lingkungan produksi yang sudah ada. model nlp menerima input dan memprediksi output untuk kasus penggunaan spesifik yang didesain untuk model tersebut. anda dapat menjalankan aplikasi nlp di data langsung dan mendapatkan output yang diperlukan.', 'nlp (natural language processing) sering sekali kita temui di kehidupan seharihari. misalnya ketika anda memesan ojek online anda harus memilih titik di peta sesuai lokasi. dengan bantuan nlp pemilihan titik lokasi menjadi lebih sesuai dan tepat. dengan semakin meningkatnya jumlah data tidak terstruktur dalam bentuk teks suara dan video setiap harinya nlp akan menjadi semakin penting untuk memahami data yang beredar di antara kita.', 'peningkatan kemampuan teknologi membuat nlp dapat diterapkan serta dikembangkan ke berbagai aplikasi penting lainnya untuk meningkatkan produktivitas manusia. mengenai hal tersebut pada artikel kali ini kami akan ulas lebih detail dan lengkap apa yang dimaksud dengan data modeling serta penggunaanya.', 'perangkat smart home pada umumnya seperti alexa dan google home saat ini semakin populer terutama di kalangan generasi muda. dilansir oleh digitized house sebanyak 58% generasi muda saat ini banyak memiliki perangkat smart home dengan kemampuan kontrol suara. smart home mudah digunakan untuk keperluan multitasking seperti anda ingin memutar musik. tak cuma itu anda sibuk memasak makan malam misalnya anda cukup menginstruksikan google home untuk mengaktifkan daftar memutar musik favorit anda kemudian perangkat itu akan melakukannya segera.', 'di sebagian besar rumah sakit atau klinik pasien akan memberikan informasi tentang gejala mereka kepada perawat atau staf di konter dan mereka akan membuat catatan untuk dibagikan ke dokter ahlinya untuk ditindaklanjuti secara. faktanya banyak rumah sakit atau klinik sekarang menggunakan nlp untuk merampingkan informasi pasien dan mengotomatiskan proses memahami kondisi pasien. untuk melakukan ini dengan menggunakan nlp biasanya rumah sakit atau klinik memungkinkan pasien berbagi pesan informasi dengan lebih cepat dan mudah.', 'natural language processing (nlp) merupakan kemampuan program komputer untuk menganalisis memahami dan memperoleh makna dari bahasa manusia dengan cara yang cerdas dan bermanfaat baik bahasa lisan maupun tulisan. dengan memanfaatkan nlp developer dapat mengatur dan menyusun pengetahuan untuk melakukan tugastugas seperti peringkasan dokumenteks otomatis menerjemahkan teks dari satu bahasa ke bahasa lain analisis sentimen named entity recognition relationship extraction dan speech recognition.', 'nlp memungkinkan komputer untuk memahami bahasa alami seperti yang dilakukan manusia. nlp menggunakan kecerdasan buatan untuk mengambil input memprosesnya dan memahaminya dengan cara yang dapat dipahami komputer. sama seperti manusia yang memiliki sensor yang berbeda  seperti telinga untuk mendengar dan mata untuk melihat  komputer memiliki program untuk membaca teks dan mikrofon untuk mengumpulkan audio.', 'natural language generation adalah proses menghasilkan frasa dan kalimat yang bermakna dalam bentuk bahasa alami. natural language generation menggunakan database untuk menentukan semantik di balik katakata dan menghasilkan teks baru. pada intinya nlg secara otomatis menghasilkan narasi yang menggambarkan meringkas atau menjelaskan input data terstruktur layaknya manusia dengan kecepatan ribuan halaman per detik. nlg dapat secara otomatis menghasilkan artikel berita atau tweet berdasarkan body teks tertentu.', 'manfaat utama nlp adalah meningkatkan cara manusia dan komputer berkomunikasi satu sama lain. cara paling langsung untuk memanipulasi komputer adalah melalui kode  bahasa komputer. dengan memungkinkan komputer untuk memahami bahasa manusia berinteraksi dengan komputer menjadi jauh lebih intuitif bagi manusia.']\n"
     ]
    }
   ],
   "source": [
    "kalimats = [content.strip() for content in dokumen.splitlines() if content]\n",
    "\n",
    "print(kalimats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c84992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281ed8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vektor = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e3291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 221)\t0.1296507029033389\n",
      "  (0, 318)\t0.1296507029033389\n",
      "  (0, 205)\t0.1296507029033389\n",
      "  (0, 48)\t0.16010525880901702\n",
      "  (0, 278)\t0.11134552969474462\n",
      "  (0, 16)\t0.0882837388391669\n",
      "  (0, 146)\t0.1296507029033389\n",
      "  (0, 184)\t0.09835780261310283\n",
      "  (0, 226)\t0.09835780261310283\n",
      "  (0, 270)\t0.0882837388391669\n",
      "  (0, 173)\t0.1296507029033389\n",
      "  (0, 142)\t0.11134552969474462\n",
      "  (0, 242)\t0.09835780261310283\n",
      "  (0, 188)\t0.08005262940450851\n",
      "  (0, 302)\t0.09835780261310283\n",
      "  (0, 130)\t0.1296507029033389\n",
      "  (0, 17)\t0.11134552969474462\n",
      "  (0, 317)\t0.11134552969474462\n",
      "  (0, 287)\t0.1296507029033389\n",
      "  (0, 152)\t0.1296507029033389\n",
      "  (0, 33)\t0.11134552969474462\n",
      "  (0, 313)\t0.1296507029033389\n",
      "  (0, 247)\t0.22269105938948924\n",
      "  (0, 79)\t0.1296507029033389\n",
      "  (0, 280)\t0.0882837388391669\n",
      "  :\t:\n",
      "  (11, 124)\t0.16163034494783612\n",
      "  (11, 155)\t0.16163034494783612\n",
      "  (11, 229)\t0.16163034494783612\n",
      "  (11, 34)\t0.16163034494783612\n",
      "  (11, 316)\t0.16163034494783612\n",
      "  (11, 148)\t0.16163034494783612\n",
      "  (11, 262)\t0.13881001776271612\n",
      "  (11, 131)\t0.13881001776271612\n",
      "  (11, 265)\t0.13881001776271612\n",
      "  (11, 41)\t0.2452374759050778\n",
      "  (11, 175)\t0.1226187379525389\n",
      "  (11, 137)\t0.11005980563404832\n",
      "  (11, 198)\t0.13881001776271612\n",
      "  (11, 133)\t0.13881001776271612\n",
      "  (11, 196)\t0.1226187379525389\n",
      "  (11, 54)\t0.14209639727750215\n",
      "  (11, 149)\t0.27336757508252635\n",
      "  (11, 158)\t0.09112252502750878\n",
      "  (11, 49)\t0.06078680377212158\n",
      "  (11, 161)\t0.13881001776271612\n",
      "  (11, 315)\t0.1125637038984491\n",
      "  (11, 125)\t0.5502990281702417\n",
      "  (11, 2)\t0.2452374759050778\n",
      "  (11, 220)\t0.07104819863875107\n",
      "  (11, 19)\t0.18224505005501757\n"
     ]
    }
   ],
   "source": [
    "matrik_tfidf = vektor.fit_transform(kalimats)\n",
    "print(matrik_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678755bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan bobot TFIDF\n",
    "Doc_Term_Matrix = pd.DataFrame(matrik_tfidf.toarray(), columns = vektor.get_feature_names())\n",
    "pd.set_option('display.precision', 2) # format angka\n",
    "hasil = Doc_Term_Matrix.to_excel('tugas-hasiltfidf.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa60dc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>58</th>\n",
       "      <th>ada</th>\n",
       "      <th>adalah</th>\n",
       "      <th>ahli</th>\n",
       "      <th>ahlinya</th>\n",
       "      <th>akan</th>\n",
       "      <th>akurasinya</th>\n",
       "      <th>alami</th>\n",
       "      <th>alexa</th>\n",
       "      <th>algoritme</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet</th>\n",
       "      <th>ucapan</th>\n",
       "      <th>ulas</th>\n",
       "      <th>umpan</th>\n",
       "      <th>umumnya</th>\n",
       "      <th>untuk</th>\n",
       "      <th>utama</th>\n",
       "      <th>video</th>\n",
       "      <th>waktu</th>\n",
       "      <th>yang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      58   ada  adalah  ahli  ahlinya  akan  akurasinya  alami  alexa  \\\n",
       "0   0.00  0.00    0.10  0.00      0.0  0.00        0.00   0.09   0.00   \n",
       "1   0.00  0.00    0.00  0.00      0.0  0.00        0.00   0.14   0.00   \n",
       "2   0.00  0.00    0.00  0.00      0.0  0.00        0.19   0.00   0.00   \n",
       "3   0.00  0.15    0.00  0.15      0.0  0.00        0.00   0.00   0.00   \n",
       "4   0.00  0.00    0.00  0.00      0.0  0.09        0.00   0.00   0.00   \n",
       "5   0.00  0.00    0.00  0.00      0.0  0.13        0.00   0.00   0.00   \n",
       "6   0.09  0.00    0.00  0.00      0.0  0.06        0.00   0.00   0.09   \n",
       "7   0.00  0.00    0.00  0.00      0.1  0.14        0.00   0.00   0.00   \n",
       "8   0.00  0.00    0.00  0.00      0.0  0.00        0.00   0.00   0.00   \n",
       "9   0.00  0.00    0.00  0.00      0.0  0.00        0.00   0.10   0.00   \n",
       "10  0.00  0.00    0.09  0.00      0.0  0.00        0.00   0.08   0.00   \n",
       "11  0.00  0.00    0.25  0.00      0.0  0.00        0.00   0.00   0.00   \n",
       "\n",
       "    algoritme  ...  tweet  ucapan  ulas  umpan  umumnya  untuk  utama  video  \\\n",
       "0        0.00  ...   0.00    0.00  0.00   0.13     0.00   0.09   0.00   0.11   \n",
       "1        0.00  ...   0.00    0.21  0.00   0.00     0.00   0.07   0.00   0.00   \n",
       "2        0.19  ...   0.00    0.00  0.00   0.00     0.00   0.13   0.00   0.00   \n",
       "3        0.00  ...   0.00    0.00  0.00   0.00     0.00   0.10   0.00   0.00   \n",
       "4        0.00  ...   0.00    0.00  0.00   0.00     0.00   0.04   0.00   0.11   \n",
       "5        0.00  ...   0.00    0.00  0.18   0.00     0.00   0.06   0.00   0.00   \n",
       "6        0.00  ...   0.00    0.00  0.00   0.00     0.09   0.06   0.00   0.00   \n",
       "7        0.00  ...   0.00    0.00  0.00   0.00     0.00   0.14   0.00   0.00   \n",
       "8        0.00  ...   0.00    0.00  0.00   0.00     0.00   0.10   0.00   0.00   \n",
       "9        0.00  ...   0.00    0.00  0.00   0.00     0.00   0.32   0.00   0.00   \n",
       "10       0.00  ...   0.12    0.00  0.00   0.00     0.00   0.04   0.00   0.00   \n",
       "11       0.00  ...   0.00    0.00  0.00   0.00     0.00   0.11   0.16   0.00   \n",
       "\n",
       "    waktu  yang  \n",
       "0    0.13  0.06  \n",
       "1    0.00  0.09  \n",
       "2    0.00  0.17  \n",
       "3    0.00  0.20  \n",
       "4    0.00  0.06  \n",
       "5    0.00  0.08  \n",
       "6    0.00  0.00  \n",
       "7    0.00  0.00  \n",
       "8    0.00  0.06  \n",
       "9    0.00  0.27  \n",
       "10   0.00  0.11  \n",
       "11   0.00  0.00  \n",
       "\n",
       "[12 rows x 320 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc_Term_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc2f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_average_score(Doc_Term_Matrix):\n",
    "    \"\"\"\n",
    "    Calculate average value of a sentence from the sentence score table.\n",
    "    \"\"\"\n",
    "    print('Finding average score')\n",
    "    hasil = []\n",
    "    for kata in range(0, len(Doc_Term_Matrix)):\n",
    "        sum = 0\n",
    "        jumkata = 0\n",
    "        for val in Doc_Term_Matrix:\n",
    "            if Doc_Term_Matrix[val][kata]>0:\n",
    "                sum += Doc_Term_Matrix[val][kata]\n",
    "                jumkata = jumkata+1\n",
    "        average = sum / jumkata\n",
    "        hasil.append(average)\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914156fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding average score\n"
     ]
    }
   ],
   "source": [
    "kalimatspd = pd.DataFrame(kalimats)\n",
    "hasilskor = pd.DataFrame(find_average_score(Doc_Term_Matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9c15ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0   0.12\n",
       "1   0.18\n",
       "2   0.17\n",
       "3   0.15\n",
       "4   0.13\n",
       "5   0.15\n",
       "6   0.11\n",
       "7   0.12\n",
       "8   0.13\n",
       "9   0.15\n",
       "10  0.12\n",
       "11  0.16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasilskor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3295c8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pemrosesan bahasa alami (nlp) adalah sebuah te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pemrosesan bahasa alami sangat penting untuk s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>para peneliti menggunakan data yang diproses s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ahli machine learning kemudian melakukan deplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nlp (natural language processing) sering sekal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>peningkatan kemampuan teknologi membuat nlp da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>perangkat smart home pada umumnya seperti alex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>di sebagian besar rumah sakit atau klinik pasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>natural language processing (nlp) merupakan ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nlp memungkinkan komputer untuk memahami bahas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>natural language generation adalah proses meng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>manfaat utama nlp adalah meningkatkan cara man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   pemrosesan bahasa alami (nlp) adalah sebuah te...\n",
       "1   pemrosesan bahasa alami sangat penting untuk s...\n",
       "2   para peneliti menggunakan data yang diproses s...\n",
       "3   ahli machine learning kemudian melakukan deplo...\n",
       "4   nlp (natural language processing) sering sekal...\n",
       "5   peningkatan kemampuan teknologi membuat nlp da...\n",
       "6   perangkat smart home pada umumnya seperti alex...\n",
       "7   di sebagian besar rumah sakit atau klinik pasi...\n",
       "8   natural language processing (nlp) merupakan ke...\n",
       "9   nlp memungkinkan komputer untuk memahami bahas...\n",
       "10  natural language generation adalah proses meng...\n",
       "11  manfaat utama nlp adalah meningkatkan cara man..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kalimatspd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd010d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              kalimat  skor\n",
      "0   pemrosesan bahasa alami (nlp) adalah sebuah te...  0.12\n",
      "1   pemrosesan bahasa alami sangat penting untuk s...  0.18\n",
      "2   para peneliti menggunakan data yang diproses s...  0.17\n",
      "3   ahli machine learning kemudian melakukan deplo...  0.15\n",
      "4   nlp (natural language processing) sering sekal...  0.13\n",
      "5   peningkatan kemampuan teknologi membuat nlp da...  0.15\n",
      "6   perangkat smart home pada umumnya seperti alex...  0.11\n",
      "7   di sebagian besar rumah sakit atau klinik pasi...  0.12\n",
      "8   natural language processing (nlp) merupakan ke...  0.13\n",
      "9   nlp memungkinkan komputer untuk memahami bahas...  0.15\n",
      "10  natural language generation adalah proses meng...  0.12\n",
      "11  manfaat utama nlp adalah meningkatkan cara man...  0.16\n"
     ]
    }
   ],
   "source": [
    "# sebelum penggabungan kalimat dan skor setiap kalimat, karena kalimat masih dalam bentuk list\n",
    "# maka kita ubah dulu menjadi dataframe\n",
    "\n",
    "hasilakhir = pd.concat([kalimatspd,hasilskor], axis=1)\n",
    "hasilakhir.columns = ['kalimat','skor']\n",
    "print(hasilakhir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0c7bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " HASIL SUMMARY :\n",
      "0     pemrosesan bahasa alami (nlp) adalah sebuah te...\n",
      "1     pemrosesan bahasa alami sangat penting untuk s...\n",
      "2     para peneliti menggunakan data yang diproses s...\n",
      "3     ahli machine learning kemudian melakukan deplo...\n",
      "4     nlp (natural language processing) sering sekal...\n",
      "5     peningkatan kemampuan teknologi membuat nlp da...\n",
      "6     perangkat smart home pada umumnya seperti alex...\n",
      "7     di sebagian besar rumah sakit atau klinik pasi...\n",
      "8     natural language processing (nlp) merupakan ke...\n",
      "9     nlp memungkinkan komputer untuk memahami bahas...\n",
      "10    natural language generation adalah proses meng...\n",
      "11    manfaat utama nlp adalah meningkatkan cara man...\n",
      "Name: kalimat, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(' HASIL SUMMARY :')\n",
    "Filter = hasilakhir.loc[hasilakhir['skor']>=0.04]\n",
    "print(Filter['kalimat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7179a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
